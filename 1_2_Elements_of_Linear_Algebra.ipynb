{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.2 Elements of Linear Algebra.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNYnDgG6AuPxy7xkJ+G+Hfy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madonnaojorin/MAT494/blob/main/1_2_Elements_of_Linear_Algebra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HBCUvR8JAIr"
      },
      "source": [
        "## Python for Linear Algebra\n",
        "The main package for linear algebra in Python is the SciPy subpackage scipy.linalg which builds on NumPy. <br>\n",
        "Import both packages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLArd67lJTIE"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.linalg as la"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf5FpUWgJdOs"
      },
      "source": [
        "### Numpy Arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcxCbixFJcYs",
        "outputId": "a6473b7d-9ac8-45d2-ebe6-597dfbb0402b"
      },
      "source": [
        "a = np.array([1,3,-2,1])  # Creating a 1D Numpy array\n",
        "print(a)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1  3 -2  1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KClRz2ZgJlPN",
        "outputId": "c24007e9-022d-4e7d-ed16-3c139526a65d"
      },
      "source": [
        "print(a.ndim)   # Dimension of array a"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHvHJcwSJl4j"
      },
      "source": [
        "print(a.shape)  # Shape of array a. In this case only the length is shown because it is a 1D array "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnVT8fbJJpb6"
      },
      "source": [
        "print(a.size)   # Size or number of elements of array a "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDD5vGFaJrLK",
        "outputId": "6768cd02-c595-4902-dcb6-a1c41a68e8e2"
      },
      "source": [
        "b = np.array([[1,2],[3,7],[-1,5]])   # 2D Numpy array (matrix)\n",
        "print(b)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1  2]\n",
            " [ 3  7]\n",
            " [-1  5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuZamAvaJtFY"
      },
      "source": [
        "print(b.ndim)   # Dimension of matix b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWYNhfAqJtxc"
      },
      "source": [
        "print(b.shape)  # Shape of matrix b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4fp2h9gJwXx"
      },
      "source": [
        "print(b.size)    # Size or number of elements of matrix b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WvC46uRJybQ",
        "outputId": "0367ef38-f62a-4eca-dbf4-45d841d4f1d0"
      },
      "source": [
        "col = b[:,0]    # Selecting the first column of matrix b\n",
        "print(col)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1  3 -1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC1eohhizVMu"
      },
      "source": [
        "##1.2.1 Linear Spaces\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAGHIQ8TzdCg"
      },
      "source": [
        "###1.2.1.1 Linear Combinations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvjogtIZ0Lyz"
      },
      "source": [
        "A linear combination is an expression constructed from a subset by multiplying each term by a constant and adding the results. We begin with the concept of a linear subspace."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piNHAwGH0ZLu"
      },
      "source": [
        "####Definition 1.2.1 (Linear subspace)<br>\n",
        "A linear subspace of $V$ is a subset $U\\subset V$ that is closed under vector addition and scalar multiplication. That is, for all $\\textbf{u}_1,\\textbf{u}_2\\in U$ and $\\alpha \\in \\mathbb{R}$, it holds that $$\\textbf{u}_1+\\textbf{u}_2\\in U\\hspace{3mm} \\text{and}\\hspace{3mm} \\alpha \\textbf{u}_1\\in U.$$<br>\n",
        "In particular, $\\textbf{0}$ is always in a linear subspace. We now introduce the concept of span."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Sd-oZGtnJNs",
        "outputId": "eac475a7-66d9-4d11-c6b3-3953ed67b625"
      },
      "source": [
        "u1 = np.array([1,2])\n",
        "u2 = np.array([3,4])\n",
        "print(u1+u2,'is also in U')\n",
        "alpha = 2\n",
        "print(alpha*u1, 'is also in U')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4 6] is also in U\n",
            "[2 4] is also in U\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCrrGyyK1dUu"
      },
      "source": [
        "####Definition 1.2.2 (Span)<br>\n",
        "Let $\\textbf{w}_1,\\cdots,\\textbf{w}_m\\in V$. The span of $\\{\\textbf{w}_1,\\cdots,\\textbf{w}_m\\}$, denoted $\\text{span}(\\textbf{w}_1,\\cdots,\\textbf{w}_m)$, is the set of all linear combinations of the $\\textbf{w}_j$â€™s. That is,\n",
        "$$\\text{span}(\\textbf{w}_1,\\cdots,\\textbf{w}_m)=\\left\\{\\sum_{j=1}^m\\alpha_j\\textbf{w}_j:\\alpha_1,\\cdots,\\alpha_m\\in\\mathbb{R}\\right\\}.$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqiU7Huk2JkX"
      },
      "source": [
        "####Lemma 1.2.3 (Every Span is a Linear Subspace)<br>\n",
        "Let $W=\\text{span}(\\textbf{w}_1,\\cdots,\\textbf{w}_m)$. Then $W$ is a linear subspace."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Xc5S27-0stq"
      },
      "source": [
        "Proof:<br>\n",
        "To show that $W$ is a linear subspace, we need to show that $\\alpha \\textbf{u}_1+\\textbf{u}_2\\in W$ for $\\textbf{u}_1,\\textbf{u}_2\\in W$ and $\\alpha\\in\\mathbb{R}$. Then\n",
        "$$\\textbf{u}_1=\\sum_{j=1}^m\\beta_{1,j}\\textbf{w}_j\\hspace{3mm}\\text{and}\\hspace{3mm}\\textbf{u}_2=\\sum_{j=1}^m\\beta_{2,j}\\textbf{w}_j$$ \n",
        "and\n",
        "$$\\alpha \\textbf{u}_1+\\textbf{u}_2=\\alpha\\sum_{j=1}^m\\beta_{1,j}\\textbf{w}_j+\\sum_{j=1}^m\\beta_{2,j}\\textbf{w}_j=\\sum_{j=1}^m(\\alpha\\beta_{1,j}+\\beta_{2,j})\\textbf{w}_j.$$\n",
        "Since $\\alpha\\beta_{1,j}+\\beta_{2,j}\\in\\mathbb{R}$, $\\sum_{j=1}^m(\\alpha\\beta_{1,j}+\\beta_{2,j})\\textbf{w}_j \\in W$.<br>\n",
        "Therefore, $\\alpha \\textbf{u}_1+\\textbf{u}_2\\in W$. $\\square$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfRYAgka4BWn"
      },
      "source": [
        "####Example\n",
        "\\begin{equation}\n",
        "u_1=w_1+2w_2\\\\\n",
        "u_2=3w_1+4w_2\\\\\n",
        "2u_1+u_2=2(w_1+2w_2)+3w_1+4w_2=5w_1+8w_2\\in W\n",
        "\\end{equation}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6CautDF3hcE"
      },
      "source": [
        "####Definition 1.2.4 (Column space)<br>\n",
        "Let $\\textbf{A}\\in \\mathbb{R}^{n\\times m}$ be an $n\\times m$ matrix with columns $\\textbf{a}_1,\\cdots,\\textbf{a}_m\\in \\mathbb{R}^n$. The column space of $\\textbf{A}$, denoted $\\text{col}(\\textbf{A})$, is the span of the columns of $\\textbf{A}$, that is, $\\text{col}(\\textbf{A})=\\text{span}(\\textbf{a}_1,\\cdots,\\textbf{a}_m)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-72vrNcSznYD"
      },
      "source": [
        "###1.2.1.2 Linear Independence and Dimension"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2GyY0nI37pC"
      },
      "source": [
        "####Definition 1.2.5 (Linear Independence)<br>\n",
        "A list of vectors $\\textbf{u}_1,\\cdots,\\textbf{u}_m$ is linearly independent if none of them can be written as a linear combination of the others, that is,\n",
        "$$\\forall i,\\textbf{u}_i\\notin \\text{span}(\\{\\textbf{u}_j:j\\neq i\\}).$$\n",
        "A list of vectors is called linearly dependent if it is not linearly independent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7ocbWss4Mh1"
      },
      "source": [
        "####Lemma 1.2.6<br>\n",
        "The vectors $\\textbf{u}_1,\\cdots,\\textbf{u}_m$ are linearly independent if and only if $$\\sum_{j=1}^m\\alpha_j\\textbf{u}_j=0 \\Rightarrow \\alpha_j=0, \\forall j.$$\n",
        "Equivalently, $\\textbf{u}_1,\\cdots,\\textbf{u}_m$ are linearly dependent if and only if there exist $\\alpha_j$â€™s, not all zero, such that $\\sum_{j=1}^m\\alpha_j\\textbf{u}_j=\\textbf{0}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voC7pIHk45c8"
      },
      "source": [
        "####Definition 1.2.7<br>\n",
        "Let $U$ be a linear subspace of $V$. A basis of $U$ is a list of vectors $\\textbf{u}_1,\\cdots, \\textbf{u}_m$ in $U$ that: (1) span $U$, that is, $U=\\text{span}(\\textbf{u}_1,\\cdots,\\textbf{u}_m)$; and (2) are linearly independent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uCJxTES5L_L"
      },
      "source": [
        "####Theorem 1.2.8 (Dimension Theorem)<br>\n",
        "Let $U$ be a linear subspace of $V$. Any basis of $U$ always has the same number of elements. All bases of $U$ have the same length, that is, the same number of elements. We call this number the dimension of $U$ and denote it $\\text{dim}(U)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Al3gYAL5tD1"
      },
      "source": [
        "####Lemma 1.2.9 (Characterization of Linearly Dependent Sets)<br>\n",
        "Let $\\textbf{u}_1,\\cdots,u_m$ be a linearly dependent list of vectors with linearly independent subset, $\\textbf{u}_i,i\\in\\{1,\\cdots,k\\},k<m$. Then there is an $i>k$ such that:\n",
        "\n",
        "1.  $\\textbf{u}_i\\in \\text{span}(\\textbf{u}_1,\\cdots,\\textbf{u}_{iâˆ’1})$\n",
        "2.  $\\text{span}(\\{\\textbf{u}_j:j\\in \\{1,\\cdots,m\\})=span(\\{\\textbf{u}_j:j\\in\\{1,\\cdots,m\\},j\\neq i\\})$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8kukkPFznwY"
      },
      "source": [
        "##1.2.2 Orthogonality\n",
        "###1.2.2.1 Orthonormal Bases\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "099RNe1q6eH8"
      },
      "source": [
        "####Definition 1.2.10 (Norm and Inner Product)<br>\n",
        "$\\langle\\textbf{u},\\textbf{v}\\rangle=\\textbf{u}\\cdot \\textbf{v} =\\sum_{1}^n \\textbf{u}_i \\textbf{v}_i$ and $||\\textbf{u}||=\\sqrt{\\sum_{1}^n \\textbf{u}_i^2}$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Faej1G6CLttL",
        "outputId": "0607ca48-fcfa-4e10-d222-42b3ad813cdb"
      },
      "source": [
        "u = np.array([1,2])\n",
        "v = np.array([3,4])\n",
        "# Inner product\n",
        "LHS = u@v\n",
        "RHS = u[0]*v[0]+u[1]*v[1]\n",
        "print(LHS ,'is equal to ', RHS)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11 is equal to  11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FStvNrfnpHIu",
        "outputId": "d27d0e6b-299c-49c0-917b-145cb2310584"
      },
      "source": [
        "# Norm\n",
        "import math\n",
        "LHS2 = math.sqrt(u1[0]**2+u1[1]**2)\n",
        "RHS2 = np.linalg.norm(u1)\n",
        "print(LHS2 ,'is equal to ', RHS2)\n",
        "# The following also gives the norm\n",
        "RHS3 = math.sqrt(u1@u1)\n",
        "print(RHS3)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9999999999999999 is equal to  0.9999999999999999\n",
            "0.9999999999999999\n",
            "[0.25 0.75]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv5KCRw-8P6G"
      },
      "source": [
        "####Definition 1.2.11 <br>\n",
        "A list of vectors $\\{\\textbf{u}_1,\\cdots,\\textbf{u}_m\\}$ is orthonormal if the $\\textbf{u}_i$â€™s are pairwise orthogonal and each has norm 1, that is for all $i$ and all $j\\neq i, \\langle\\textbf{u}_i,\\textbf{u}_j\\rangle=0$ and $||\\textbf{u}_i||=1$. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLPKjr5yCPPI"
      },
      "source": [
        "Example: Show $S  =  \\{(1/2,\\sqrt{3}/2), (-\\sqrt{3}/2, 1/2)\\}$\n",
        "are an orthonormal set of vectors in $\\mathbb{R}^3$. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fYTXNMJCJ2Z",
        "outputId": "0b7eb1cc-d6eb-4986-b97d-ab0a148d0918"
      },
      "source": [
        "u1=np.array([1/2,math.sqrt(3)/2])\n",
        "u2=np.array([-math.sqrt(3)/2,1/2])\n",
        "print(u1@u2)\n",
        "print(np.linalg.norm(u1))\n",
        "print(np.linalg.norm(u2))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "0.9999999999999999\n",
            "0.9999999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcVcyYGy84Gc"
      },
      "source": [
        "####Lemma 1.2.12<br>\n",
        "Let $\\{\\textbf{u}_1,\\cdots,\\textbf{u}_m\\}$ be an orthonormal list of vectors.\n",
        "1.   $||\\sum_{j=1}^m \\alpha_j\\textbf{u}_j||^2=\\sum_{j=1}^m \\alpha_j^2$ for any $\\alpha_j\\in\\mathbb{R},j\\in\\{1,\\cdots,m\\}$\n",
        "2.  $\\{\\textbf{u}_1,\\cdots,\\textbf{u}_m\\}$ are linearly independent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKP4mzMv9JKr"
      },
      "source": [
        "####Theorem 1.2.13 (Orthonormal Basis Expansion)<br>\n",
        "Let $\\textbf{q}_1,\\cdots,\\textbf{q}_m$ be an orthonormal basis of $\\mathscr{U}$ and let $\\textbf{u}\\in \\mathscr{U}$. Then $$\\textbf{u}=\\sum_{j=1}^m\\langle\\textbf{u},\\textbf{q}_j\\rangle\\textbf{q}_j.$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UF9HwdnDsoe"
      },
      "source": [
        "Example: Find the coordinates for the vector $(5,10)$ with respect to the basis \n",
        "$S  =  \\{(3/5, 4/5), (-4/5, 3/5)\\}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5EpX-V4GXOu",
        "outputId": "4074dce3-2d9e-4a70-8eac-44208e473e3e"
      },
      "source": [
        "q1=np.array([3/5,4/5])\n",
        "q2=np.array([-4/5,3/5])\n",
        "u=np.array([5,10])\n",
        "print(u@q1)\n",
        "print(u@q2)\n",
        "print('[(5,10)]_s= (',round(u@q1),',',round(u@q2),')')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11.0\n",
            "1.9999999999999998\n",
            "[(5,10)]_s= ( 11 , 2 )\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sph7ijbzzn9P"
      },
      "source": [
        "###1.2.2.2 Best Approximation Theorem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quKfKe2a9m1o"
      },
      "source": [
        "####Example 1.2.14<br>\n",
        "Consider the two-dimensional case with a one-dimensional subspace, say $\\mathscr{U}=\\text{span}(\\textbf{u}_1)$ with $||\\textbf{u}_1=1||$. The geometrical intuition is in Figure 1.1. The solution $\\textbf{v}^*$ has the property that the difference $\\textbf{v}-\\textbf{v}^*$ makes a right angle with $\\textbf{u}_1$, that is, it is orthogonal to it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynpDscPd-K91"
      },
      "source": [
        "####Definition 1.2.15 (Orthogonal Projection)<br>\n",
        "Let $U\\subset V$ be a linear subspace with orthonormal basis $\\textbf{q}_1,\\cdots,\\textbf{q}_m$. The orthogonal projection of $\\textbf{v}\\in V$ on $U$ is defined as $$\\mathscr{P}_{\\mathscr{U}}\\textbf{v}=\\sum_{j=1}^m\\langle\\textbf{v},\\textbf{q}_j\\rangle\\textbf{q}_j$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "422JA5xw-ex6"
      },
      "source": [
        "####Theorem 1.2.16 (Best Approximation Theorem)<br>\n",
        "Let $\\mathscr{U}\\subseteq V$ be a linear subspace with orthonormal basis $\\textbf{q}_1,\\cdots,\\textbf{q}_m$ and let $\\textbf{v}\\in V$. For any $\\textbf{u}\\in \\mathscr{U}$ $$||\\textbf{v}-\\mathscr{P}_{\\mathscr{U}}\\textbf{v}||\\leq||\\textbf{v}-\\textbf{u}||.$$\n",
        "Furthermore, if $\\textbf{u}\\in \\mathscr{U}$ and the inequality above is an equality, then $\\mathscr{U}=\\mathscr{P}_{\\mathscr{U}}\\textbf{v}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WEE5r5v_TF0"
      },
      "source": [
        "####Lemma 1.2.17 (Pythagorean theorem)<br>\n",
        "Letu, $\\textbf{u},\\textbf{v}\\in V$ be orthogonal. Then $||\\textbf{u}+\\textbf{v}||^2=||\\textbf{u}||^2+||\\textbf{v}||^2$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WVUN7kF_meB"
      },
      "source": [
        "####Lemma 1.2.18 (Cauchy-Schwarz)<br>\n",
        "For any $\\textbf{u},\\textbf{v}\\in V,|\\langle\\textbf{u},\\textbf{v}\\rangle|\\leq||\\textbf{u}||||\\textbf{v}||$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3W_QkRxP_6Z9"
      },
      "source": [
        "####Lemma 1.2.19 (Orthogonal Decomposition)<br>\n",
        "Let $\\mathscr{U}\\subseteq \\textbf{V}$ be a linear subspace with orthonormal basis $\\textbf{q}_1,\\cdots,\\textbf{q}_m$ and let $\\textbf{v}\\in V$. For any $\\textbf{u}\\in \\mathscr{U}, \\langle\\textbf{v}-\\mathscr{P}_{\\mathscr{U}}\\textbf{v},\\textbf{u}\\rangle=0$. In particular, $\\textbf{v}$ can be decomposed as $(\\textbf{v}-\\mathscr{P}_{\\mathscr{U}}\\textbf{v})+\\mathscr{P}_{\\mathscr{U}}\\textbf{v}$ where the two terms are orthogonal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGMHQCNoL2K8"
      },
      "source": [
        "### Matrix Powers\n",
        "There is no symbol for matrix powers that we can use, so we must import the function matrix_power from the subpackage numpy.linalg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFgFSrjiL14y"
      },
      "source": [
        "from numpy.linalg import matrix_power as mpow"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU3efRavLxn6",
        "outputId": "f45ee0c7-0b73-4e3f-e883-0c65203cdafa"
      },
      "source": [
        "M = np.array([[3,4],[-1,5]])\n",
        "print(M)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 3  4]\n",
            " [-1  5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pX3owXvL87h",
        "outputId": "34400ec0-a727-42aa-bed9-f1365a769a19"
      },
      "source": [
        "print(mpow(M,2))  # Matrix M to the power 2"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 5 32]\n",
            " [-8 21]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GY2y4sWoL-YI",
        "outputId": "2065e275-015c-4d83-cf50-7ef89075a1da"
      },
      "source": [
        "print(M @ M)     # Cheking the result is the same with the multiplication operator"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 5 32]\n",
            " [-8 21]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0NEBQQOzoIf"
      },
      "source": [
        "##1.2.3 Eigenvalues and Eigenvectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEcLmLVuAQkl"
      },
      "source": [
        "####Definition 1.2.20(Eigenvalues and eigenvectors)<br>\n",
        "Let $A\\in \\mathbb{R} ^{dÃ—d}$ be a square matrix. Then $\\lambda\\in \\mathbb{R}$ is an eigenvalue of $\\textbf{A}$ if there exists a nonzero vector $\\textbf{x}\\neq \\textbf{0}$ such that $\\textbf{Ax=Î»x}$.<br>\n",
        "The vector $\\textbf{x}$ is referred to as an eigenvector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnPDOfWYAuni"
      },
      "source": [
        "####Example 1.2.21(No Real Eigenvalues): <br>\n",
        "Set $d=2$ and let \n",
        "$$\\textbf{A}=\\begin{pmatrix}\n",
        "0 & -1\\\\\n",
        "1&0\n",
        "\\end{pmatrix}$$\n",
        "\n",
        "For $\\lambda$ to be an eigenvalue, there must be an nonzero eigenvector $\\textbf{x}=(x_1,x_2)^T$ such that $\\textbf{Ax}=\\lambda \\textbf{x}$ or put differently $âˆ’x_2=\\lambda x_1$ and $x_1=\\lambda x_2$. <br>\n",
        "Replacing these equations into each other, it must be that $âˆ’x_2=\\lambda^2x_2$ and $x_1=âˆ’\\lambda^2x_1$. Because $x_1,x_2$ cannot both be 0, $\\lambda$ must satisfy the equation $\\lambda^2=-1$ for which there is no real solution.<br>\n",
        "In general, $A\\in\\mathbb{R}^{dÃ—d}$ has at most $d$ distinct eigenvalues."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EefKB0EeKzRD",
        "outputId": "8d134d64-39b2-4388-b8c3-71a967fa4d62"
      },
      "source": [
        "### Basic matrix operations in Python\n",
        "M = np.array([[3,4],[-1,5]])\n",
        "print(M)\n",
        "\n",
        "#Transpose \n",
        "print('Transpose is \\n', M.T)\n",
        "\n",
        "#Inverse\n",
        "print('Inverse is \\n',la.inv(M))\n",
        "\n",
        "#Trace\n",
        "print('Trace is \\n',np.trace(M))\n",
        "\n",
        "#Determinant\n",
        "print('Determinant is \\n',la.det(M))\n",
        "\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 3  4]\n",
            " [-1  5]]\n",
            "Transpose is \n",
            " [[ 3 -1]\n",
            " [ 4  5]]\n",
            "Inverse is \n",
            " [[ 0.26315789 -0.21052632]\n",
            " [ 0.05263158  0.15789474]]\n",
            "Trace is \n",
            " 8\n",
            "Determinant is \n",
            " 19.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNfHWicRBgvw"
      },
      "source": [
        "####Lemma 1.2.22 (Number of Eigenvalues):<br>\n",
        "Let $\\textbf{A}\\in \\mathbb{R}^{d\\times d}$ and let $\\lambda_1,\\cdots,\\lambda_m$ be distinct eigenvalues of $\\textbf{A}$ with corresponding nonzero eigenvectors $\\textbf{x}_1,\\cdots,\\textbf{x}_m$. Then $\\textbf{x}_1,\\cdots ,\\textbf{x}_m$ are linearly independent. As a result, $m\\leq d$. \\\\"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swjPXhEoB1jp"
      },
      "source": [
        "###1.2.3.1 Diagonalization of Symmetric Matrices\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ-g_c-KB-0g"
      },
      "source": [
        "####Example 1.2.23 (Diagonal (and Similar) Matrices) <br>\n",
        "Let $A$ be similar to a matrix $D=\\text{diag}(\\lambda_1,\\cdots,\\lambda_d)$ with distinct diagonal entries, that is, there exists an on singular matrix $P$ such that $A=PDP^{âˆ’1}$. Let $\\textbf{p}_1,\\cdots,\\textbf{p}_d$ be the columns of $\\textbf{P}$. Then $\\textbf{AP}=\\textbf{PD}$ which implies that $\\textbf{Ap}_i=\\lambda_i\\textbf{p}_i$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s73-ejjECW8G"
      },
      "source": [
        "####Theorem 1.2.24<br>\n",
        "If $\\textbf{A}$ is symmetric,then any two eigenvectors from different eigenspaces are orthogonal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuCmpyeYCeuo"
      },
      "source": [
        "####Theorem 1.2.25 (The Spectral Theorem for Symmetric Matrices) <br>\n",
        "An $n\\times n$ symmetric matrix $A$ has the following properties:\n",
        "\n",
        "\n",
        "*   $A$ has $n$ real eigenvalues, counting multiplicities.\n",
        "*   If $\\lambda$ is an eigenvalues of $A$ with multiplicity $k$, then the eigenspace for $\\lambda$ is k-dimensional.\n",
        "*   The eigenspaces are mutually orthogonal, in the sense that eigenvectors corresponding to different eigenvalues are orthogonal.\n",
        "\n",
        "*  $A$ is orthogonally diagonalizable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GloCgTeQzoTw"
      },
      "source": [
        "###1.2.3.2 Constrained Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvXaKoldCdE5"
      },
      "source": [
        "####Theorem 1.2.26<br>\n",
        "Let $A$ be $n\\times n$ symmetric matrix $A$ with the an orthogonal diagonalization $tA=PDP^{âˆ’1}$. The columns of $P$ are orthonormal eigenvectors $\\textbf{v}_1,\\cdots,\\textbf{v}_n$ of $A$. Assume that the diagonal of $D$ are arranged so that $\\lambda_1\\leq\\lambda_2,\\cdots\\leq\\lambda_n$. Then $$\\min_{x\\neq 0}\\frac{\\textbf{x}^TA\\textbf{x}}{\\textbf{x}^T\\textbf{x}}=\\lambda_1$$ is achieved when $\\textbf{x}=\\textbf{v}_1$ and  $$\\min_{x\\neq 0}\\frac{\\textbf{x}^TA\\textbf{x}}{\\textbf{x}^T\\textbf{x}}=\\lambda_n$$ is achieved when $\\textbf{x}=\\textbf{v}_n$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTIMBAd7LIyL"
      },
      "source": [
        "### Eigenvalues and Eigenvectors\n",
        "The numpy.linalg.eig function returns a tuple consisting of a vector and an array. The vector contains the eigenvalues. The array contains the corresponding eigenvectors, one eigenvector per column. The eigenvectors are normalized so their Euclidean norms are 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5l3hrlSLEuC"
      },
      "source": [
        "D = np.array([[1,2,3],[3,2,1],[1,0,-1]])\n",
        "lam, v = la.eig(D)\n",
        "print(lam)\n",
        "print(v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO3ReWYWLM7H"
      },
      "source": [
        "Let's check if the eigenvalue/eigenvector condition holds:\n",
        "## $$Av = \\lambda v$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BcbVdrJLQFn"
      },
      "source": [
        "print(D*v)\n",
        "print(lam*v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox_GNlPwLYhs"
      },
      "source": [
        "### Solving Linear Systems\n",
        "Let's try to solve the following system of equations:\n",
        "\n",
        "\\begin{align}\n",
        "4x + 3y + 2z &= 25\\\\\n",
        "-2x + 2y + 3z &= -10\\\\\n",
        "3x -5y + 2z &= -4\n",
        "\\end{align}\n",
        "\n",
        "To solve a system of linear equations, we need to find the values of the $x$ and $y$ variables. There are multiple ways to solve such a system, such as Elimination of Variables, Cramer's Rule, Row Reduction Technique, and the Matrix Solution. We will use the matrix solution. In the matrix solution, the system of linear equations to be solved is represented in the form of matrix: \n",
        "\n",
        "$$ AX = B $$\n",
        "\n",
        "So, we can represent the linear system in the form of matrix as follows:\n",
        "\n",
        "\\begin{align}\n",
        "\\begin{pmatrix}\n",
        "4 & 3 & 2\\\\ \n",
        "-2 & 2 & 3\\\\\n",
        "3 & -5 & 2\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "x\\\\ \n",
        "y\\\\\n",
        "z\n",
        "\\end{pmatrix} =\n",
        "\\begin{pmatrix}\n",
        "25\\\\ \n",
        "-10\\\\\n",
        "4\n",
        "\\end{pmatrix}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZO634XgLVux"
      },
      "source": [
        "A = np.array([[4,3,2],[-2,2,3],[3,-5,2]])\n",
        "B = np.array([25,-10,-4])\n",
        "X = np.linalg.solve(A,B)\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOChQyJSxS8F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJVm14UXzUCc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVta5yu3zXTz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}